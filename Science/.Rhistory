`dc:description`, `prism:aggregationType`, `subtypeDescription`,
`authkeywords`, All_text)
#focus on specific columns and save as a csv
df <- df %>%
mutate(Year = as.numeric(str_extract(`prism:coverDate`, "\\d{4}"))) #%>%
#focus on specific columns and save as a csv
df <- df %>%
mutate(Year = as.numeric(str_extract(`prism:coverDate`, "\\d{4}"))) %>%
mutate(All_text= tolower(paste(`dc:title`, `dc:description`, `authkeywords`)))%>%
select(Year, `dc:title`, `prism:publicationName`,
`dc:description`, `prism:aggregationType`, `subtypeDescription`,
`authkeywords`, All_text)
colnames(df) <- c("Year", "Title", "Publication", "Abstract", "Pub_Type",
"Subtype", "Keywords", "All_text")
write.csv(df, "All_articles_slim.csv")
df <- df %>%
mutate(has_term = ifelse(grepl(word, All_text),1,0))
df <- df %>%
mutate(has_term = map_int(All_text, ~ifelse(grepl(word, .),1,0)))
class(df$All_text)
word <- "alcohol"
df <- df %>%
mutate(has_term = map_int(All_text, ~ifelse(grepl(word, .),1,0)))
df <- df %>%
mutate(has_term = map_dbl(All_text, ~ifelse(grepl(word, .),1,0)))
View(df)
df <- df %>%
mutate(has_term = map_dbl(All_text, ~ifelse(grepl(word, .),1,0))) %>%
group_by(year) %>%
summarise(has_term = sum(has_term),
total = n())%>%
mutate(prop = has_term/total)
df <- df %>%
mutate(has_term = map_dbl(All_text, ~ifelse(grepl(word, .),1,0))) %>%
group_by(Year) %>%
summarise(has_term = sum(has_term),
total = n())%>%
mutate(prop = has_term/total)
df %>%
ggplot(aes(x = Year, y = prop))+
geom_line()+
theme_minimal()+
labs(title = paste0("Proportion of articles on a topic that are also about ", term))
term <- "alcohol"
df %>%
ggplot(aes(x = Year, y = prop))+
geom_line()+
theme_minimal()+
labs(title = paste0("Proportion of articles on a topic that are also about ", term))
df %>%
ggplot(aes(x = Year, y = prop))+
geom_line()+
theme_minimal()+
labs(title = paste0("Proportion of articles on a topic that are also about ", term))+
scale_x_continuous(breaks= pretty_breaks())
?pretty_breaks()
for (i in 1:ceiling((n-25)/25)){
#for (i in 1:100){
call <- paste0(url2, "cursor=", cursor,"&count=25&query=",query,"&apikey=",key)
ans <- fromJSON(call)
df <- df %>% bind_rows(ans$`search-results`$entry)
cursor = URLencode(ans$`search-results`$cursor$`@next`, reserved = TRUE)
}
saveRDS(df, "All_articles.Rds")
df <- df %>%
mutate(Year = as.numeric(str_extract(`prism:coverDate`, "\\d{4}"))) %>%
mutate(All_text= tolower(paste(`dc:title`, `dc:description`, `authkeywords`)))%>%
select(Year, `dc:title`, `prism:publicationName`,
`dc:description`, `prism:aggregationType`, `subtypeDescription`,
`authkeywords`, All_text)
colnames(df) <- c("Year", "Title", "Publication", "Abstract", "Pub_Type",
"Subtype", "Keywords", "All_text")
write.csv(df, "All_articles_slim.csv", row.names = FALSE)
View(df)
df2 <- df
call <- paste0(url1,"%28",query,"%29&apikey=",key, "&view=COMPLETE&cursor=*&count=25")
ans <- fromJSON(call)
n = as.integer(ans$`search-results`$`opensearch:totalResults`)
df <- ans$`search-results`$entry
#ignore this last part, it's just defining some other data
url1 <- "https://api.elsevier.com/content/search/scopus?query="
query <- "TITLE-ABS-KEY ( child AND abuse )" #add your query here
URLencode(query, reserved = TRUE)
query <- query %>%
str_replace_all("\\s", "\\+") %>%
str_replace_all("\\(", "\\%28") %>%
str_replace_all("\\)", "\\%29") %>%
str_replace_all('\\"', '\\%22')
all <- paste0(url1,"%28",query,"%29&apikey=",key, "&view=COMPLETE&cursor=*&count=25")
ans <- fromJSON(call)
n = as.integer(ans$`search-results`$`opensearch:totalResults`)
df <- ans$`search-results`$entry
View(df2)
df2 <- df[3:60752,5:34]
df2 <- df2[3:60752,5:34]
colnames(df)
colnames(df) <- c("Year", "Title", "Abstract", "Keywords", "All_text")
colnames(df) <- c("Year", "Title", "Abstract", "Keywords", "All_text")
View(df2[[14]][[1]])
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(jsonlite)
library(scales) # optional. can install by running install.packages("scales")
rm(list=ls())
total_articles <- read.csv("total_articles.csv")
subject_articles <- read.csv("subject_articles.csv")
fields <- read.csv("scopus_subjects.csv")
asjc_codes <- read.csv("asjc.csv")
files <- list.files()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(jsonlite)
library(scales) # optional. can install by running install.packages("scales")
key <- "841e8a33d2116fc1c27eace47746374c"
year_start <- 1960 #enter year that you wish to start your search
year_end <- 2021 #enter year that you wish to end your search
query <- "TITLE-ABS-KEY ( (child OR childhood) AND abuse )" #add your query here
#ignore this last part, it's just defining some other data
url <- "https://api.elsevier.com/content/search/scopus?query="
query <- query %>%
str_replace_all("\\s", "\\+") %>%
str_replace_all("\\(", "\\%28") %>%
str_replace_all("\\)", "\\%29") %>%
str_replace_all('\\"', '\\%22')
if ("article_count.csv" %in% files){
#read existing file, if any
article_count <- read.csv("article_count.csv")
} else {
#create empty data frame
article_count <- tibble(year = c(year_start:year_end), n=0)
#run search by year
for (i in 1:nrow(article_count)){
year = article_count$year[i]
call <- paste0(url,"%28+",query,"+AND+PUBYEAR+IS+",year,"+%29&apikey=",key)
ans <- fromJSON(call)
article_count$n[i] <- as.integer(ans$`search-results`$`opensearch:totalResults`)
}
#join to total scopus counts
article_count <- article_count%>%
left_join(total_articles)%>%
mutate(prop = n/total)
#save file
write.csv(article_count, "article_count.csv", row.names = FALSE)
}
View(article_count)
article_count %>%
ggplot((aes(x=year, y = n)))+
geom_line(color="#008080")+
theme_minimal() +
labs(title = "Total number of articles on the topic over time")
article_count %>%
ggplot((aes(x=year, y = prop)))+
geom_line(color="#008080")+
theme_minimal()+
labs(title = "Proportion of all Scopus articles on the topic over time")
View(fields)
if ("articles_by_subject.csv" %in% files){
#read existing file, if any
articles_by_subject <- read.csv("articles_by_subject.csv", row.names = FALSE)
} else {
#create empty data frame
articles_by_subject <- fields %>%
select(Abb) %>%
mutate(year = list(year_start:year_end))%>%
unnest(year)%>%
mutate(n=0)
# run search by subject and year
for (i in 1:nrow(articles_by_subject)){
year <- articles_by_subject$year[i]
field <-articles_by_subject$Abb[i]
call <- paste0(url,"%28+",query,"+AND+SUBJAREA+%28+",field,"+%29+AND+PUBYEAR+IS+",year,"+%29&apikey=",key)
ans <- fromJSON(call)
articles_by_subject$n[i] = as.integer(ans$`search-results`$`opensearch:totalResults`)
}
#rename columns
colnames(articles_by_subject) <- c("field", "year", "n")
#combine with total counts
articles_by_subject <- articles_by_subject %>%
left_join(subject_articles)%>%
mutate(prop = n/total)
#save file
write.csv(articles_by_subject, "articles_by_subject.csv", row.names = FALSE)
}
if ("articles_by_subject.csv" %in% files){
#read existing file, if any
articles_by_subject <- read.csv("articles_by_subject.csv")
} else {
#create empty data frame
articles_by_subject <- fields %>%
select(Abb) %>%
mutate(year = list(year_start:year_end))%>%
unnest(year)%>%
mutate(n=0)
# run search by subject and year
for (i in 1:nrow(articles_by_subject)){
year <- articles_by_subject$year[i]
field <-articles_by_subject$Abb[i]
call <- paste0(url,"%28+",query,"+AND+SUBJAREA+%28+",field,"+%29+AND+PUBYEAR+IS+",year,"+%29&apikey=",key)
ans <- fromJSON(call)
articles_by_subject$n[i] = as.integer(ans$`search-results`$`opensearch:totalResults`)
}
#rename columns
colnames(articles_by_subject) <- c("field", "year", "n")
#combine with total counts
articles_by_subject <- articles_by_subject %>%
left_join(subject_articles)%>%
mutate(prop = n/total)
#save file
write.csv(articles_by_subject, "articles_by_subject.csv", row.names = FALSE)
}
View(articles_by_subject)
cumulative_subject <- articles_by_subject %>%
group_by(field)%>%
summarise(n= sum(n)) %>%
arrange(-n) %>%
mutate(total = sum(article_count$n))%>%
mutate(prop = n/total)
head(cumulative_subject)
top_fields <- cumulative_subject[1:6,] #select how many top fields you want to display
articles_by_subject %>%
filter(field %in% top_fields$field)%>%
ggplot((aes(x=year, y = prop, color = field)))+
geom_line()+
theme_minimal() +
labs(title = "Proportion of articles in a field on the topic")
articles_by_subject %>%
filter(field %in% top_fields$field)%>%
ggplot((aes(x=year, y = prop)))+
geom_line()+
theme_minimal()+
facet_wrap(~field, scales = "free")+
labs(title = "Proportion of articles in a field on the topic")
View(asjc_codes)
ASJC_list <- c("2735", "3312") # include your ASJC code. if you want to look at more than one code, you should separate them like this c("code1", "code2")
#this code will look for both all articles within a code
#and articles within a code on the particular prolem
if ("articles_by_asjc.csv" %in% files){
#read existing file, if any
articles_by_asjc <- read.csv("articles_by_asjc.csv")
} else {
#create empty df
articles_by_asjc <- tibble(year = c(year_start:year_end), asjc = list(ASJC_list), total=0, n=0) %>%
unnest(asjc)
#run search by year
for (i in 1:nrow(articles_by_asjc)){
year = articles_by_asjc$year[i]
asjc = articles_by_asjc$asjc[i]
#look for total articles
call <- paste0(url,"%28+SUBJTERMS+%28+",asjc,"+%29+AND+PUBYEAR+IS+",year,"+%29&apikey=",key)
ans <- fromJSON(call)
articles_by_asjc$total[i] <- as.integer(ans$`search-results`$`opensearch:totalResults`)
#look for articles on topic
call <- paste0(url,"%28+",query,"+AND+SUBJTERMS+%28+",asjc,"+%29+AND+PUBYEAR+IS+",year,"+%29&apikey=",key)
ans <- fromJSON(call)
articles_by_asjc$n[i] <- as.integer(ans$`search-results`$`opensearch:totalResults`)
}
articles_by_asjc <- articles_by_asjc %>%
mutate(prop = n/total)
write.csv(articles_by_asjc, "articles_by_asjc.csv")
}
articles_by_asjc %>%
ggplot((aes(x=year, y = prop, color = asjc)))+
geom_line()+
theme_minimal() +
labs(title = "Proportion of articles in a field on the topic")+
scale_x_continuous(breaks= pretty_breaks())
articles_by_asjc %>%
ggplot((aes(x=year, y = prop)))+
geom_line()+
theme_minimal()+
facet_wrap(~asjc, scales = "free")+
labs(title = "Proportion of articles in a field on the topic")+
scale_x_continuous(breaks= pretty_breaks())
articles_by_asjc %>%
ggplot((aes(x=year, y = prop, color = as.character(asjc)))+
geom_line()+
theme_minimal() +
labs(title = "Proportion of articles in a field on the topic")+
scale_x_continuous(breaks= pretty_breaks())
articles_by_asjc %>%
articles_by_asjc %>%
ggplot((aes(x=year, y = prop, color = as.character(asjc))))+
geom_line()+
theme_minimal() +
labs(title = "Proportion of articles in a field on the topic")+
scale_x_continuous(breaks= pretty_breaks())
articles_by_asjc %>%
ggplot((aes(x=year, y = prop)))+
geom_line()+
theme_minimal()+
facet_wrap(~asjc, scales = "free")+
labs(title = "Proportion of articles in a field on the topic")+
scale_x_continuous(breaks= pretty_breaks())
call <- paste0(url1,"%28",query,"%29&apikey=",key, "&view=COMPLETE&cursor=*&count=25")
ans <- fromJSON(call)
n = as.integer(ans$`search-results`$`opensearch:totalResults`)
df <- ans$`search-results`$entry
cursor = URLencode(ans$`search-results`$cursor$`@next`, reserved = TRUE)
url2 <- "https://api.elsevier.com/content/search/scopus?"
df <- read.csv("All_articles_slim.csv")
View(df)
key <- "841e8a33d2116fc1c27eace47746374c"
query <- "TITLE-ABS-KEY ( child AND abuse )" #add your query here
#ignore this last part, it's just defining some other data
url1 <- "https://api.elsevier.com/content/search/scopus?query="
query <- query %>%
str_replace_all("\\s", "\\+") %>%
str_replace_all("\\(", "\\%28") %>%
str_replace_all("\\)", "\\%29") %>%
str_replace_all('\\"', '\\%22')
call <- paste0(url1,"%28",query,"%29&apikey=",key, "&view=COMPLETE&cursor=*&count=25")
ans <- fromJSON(call)
n = as.integer(ans$`search-results`$`opensearch:totalResults`)
df <- ans$`search-results`$entry
cursor = URLencode(ans$`search-results`$cursor$`@next`, reserved = TRUE)
url2 <- "https://api.elsevier.com/content/search/scopus?"
#  scrape all data
for (i in 1:100){
#for (i in 1:100){
call <- paste0(url2, "cursor=", cursor,"&count=25&query=",query,"&apikey=",key)
ans <- fromJSON(call)
df <- df %>% bind_rows(ans$`search-results`$entry)
cursor = URLencode(ans$`search-results`$cursor$`@next`, reserved = TRUE)
}
saveRDS(df, "All_articles.Rds")
View(df)
df <- df %>%
mutate(Year = as.numeric(str_extract(`prism:coverDate`, "\\d{4}"))) %>%
mutate(All_text= tolower(paste(`dc:title`, `dc:description`, `authkeywords`)))%>%
select(Year, `dc:title`, `prism:publicationName`,
`dc:description`, `prism:aggregationType`, `subtypeDescription`,
`authkeywords`, All_text)
colnames(df) <- c("Year", "Title", "Publication", "Abstract", "Pub_Type",
"Subtype", "Keywords", "All_text")
write.csv(df, "All_articles_slim.csv", row.names = FALSE)
term <- "alcohol"
df <- df %>%
mutate(has_term = map_dbl(All_text, ~ifelse(grepl(term, .),1,0))) %>%
group_by(Year) %>%
summarise(has_term = sum(has_term),
total = n())%>%
mutate(prop = has_term/total)
df %>%
ggplot(aes(x = Year, y = prop))+
geom_line()+
theme_minimal()+
labs(title = paste0("Proportion of articles on a topic that are also about ", term))+
scale_x_continuous(breaks= pretty_breaks())
rm(list=ls())
key <- "4ac7d025db4d4706c106aa0f3de643a2"
query <- "TITLE-ABS-KEY ( child AND abuse )" #add your query here
#ignore this last part, it's just defining some other data
url1 <- "https://api.elsevier.com/content/search/scopus?query="
query <- query %>%
str_replace_all("\\s", "\\+") %>%
str_replace_all("\\(", "\\%28") %>%
str_replace_all("\\)", "\\%29") %>%
str_replace_all('\\"', '\\%22')
call <- paste0(url1,"%28",query,"%29&apikey=",key, "&view=COMPLETE&cursor=*&count=25")
ans <- fromJSON(call)
n = as.integer(ans$`search-results`$`opensearch:totalResults`)
df <- ans$`search-results`$entry
cursor = URLencode(ans$`search-results`$cursor$`@next`, reserved = TRUE)
call <- paste0(url1,"%28",query,"%29&apikey=",key, "&view=COMPLETE&cursor=*&count=25")
ans <- fromJSON(call)
ans <- fromJSON(call)
n = as.integer(ans$`search-results`$`opensearch:totalResults`)
df <- ans$`search-results`$entry
cursor = URLencode(ans$`search-results`$cursor$`@next`, reserved = TRUE)
url2 <- "https://api.elsevier.com/content/search/scopus?"
#  scrape all data
for (i in 1:ceiling((n-25)/25)){
#for (i in 1:100){
call <- paste0(url2, "cursor=", cursor,"&count=25&query=",query,"&apikey=",key)
ans <- fromJSON(call)
df <- df %>% bind_rows(ans$`search-results`$entry)
cursor = URLencode(ans$`search-results`$cursor$`@next`, reserved = TRUE)
}
saveRDS(df, "All_articles.Rds")
df <- df %>%
mutate(Year = as.numeric(str_extract(`prism:coverDate`, "\\d{4}"))) %>%
mutate(All_text= tolower(paste(`dc:title`, `dc:description`, `authkeywords`)))%>%
select(Year, `dc:title`, `prism:publicationName`,
`dc:description`, `prism:aggregationType`, `subtypeDescription`,
`authkeywords`, All_text)
colnames(df) <- c("Year", "Title", "Publication", "Abstract", "Pub_Type",
"Subtype", "Keywords", "All_text")
write.csv(df, "All_articles_slim.csv", row.names = FALSE)
term <- "alcohol"
df <- df %>%
mutate(has_term = map_dbl(All_text, ~ifelse(grepl(term, .),1,0))) %>%
group_by(Year) %>%
summarise(has_term = sum(has_term),
total = n())%>%
mutate(prop = has_term/total)
df %>%
ggplot(aes(x = Year, y = prop))+
geom_line()+
theme_minimal()+
labs(title = paste0("Proportion of articles on a topic that are also about ", term))+
scale_x_continuous(breaks= pretty_breaks())
term <- "maltreatment"
df <- df %>%
mutate(has_term = map_dbl(All_text, ~ifelse(grepl(term, .),1,0))) %>%
group_by(Year) %>%
summarise(has_term = sum(has_term),
total = n())%>%
mutate(prop = has_term/total)
df %>%
ggplot(aes(x = Year, y = prop))+
geom_line()+
theme_minimal()+
labs(title = paste0("Proportion of articles on a topic that are also about ", term))+
scale_x_continuous(breaks= pretty_breaks())
term <- "maltreatment"
df <- df %>%
mutate(has_term = map_dbl(All_text, ~ifelse(grepl(term, .),1,0))) %>%
group_by(Year) %>%
summarise(has_term = sum(has_term),
total = n())%>%
mutate(prop = has_term/total)
df <- read.csv("All_articles_slim.csv")
term <- "maltreatment"
df <- df %>%
mutate(has_term = map_dbl(All_text, ~ifelse(grepl(term, .),1,0))) %>%
group_by(Year) %>%
summarise(has_term = sum(has_term),
total = n())%>%
mutate(prop = has_term/total)
term <- "maltreatment"
df %>%
mutate(has_term = map_dbl(All_text, ~ifelse(grepl(term, .),1,0))) %>%
group_by(Year) %>%
summarise(has_term = sum(has_term),
total = n())%>%
mutate(prop = has_term/total)%>%
ggplot(aes(x = Year, y = prop))+
geom_line()+
theme_minimal()+
labs(title = paste0("Proportion of articles on a topic that are also about ", term))+
scale_x_continuous(breaks= pretty_breaks())
df <- read.csv("All_articles_slim.csv")
df %>%
mutate(has_term = map_dbl(All_text, ~ifelse(grepl(term, .),1,0))) %>%
group_by(Year) %>%
summarise(has_term = sum(has_term),
total = n())%>%
mutate(prop = has_term/total)%>%
ggplot(aes(x = Year, y = prop))+
geom_line()+
theme_minimal()+
labs(title = paste0("Proportion of articles on a topic that are also about ", term))+
scale_x_continuous(breaks= pretty_breaks())
df %>%
mutate(has_term = map_dbl(All_text, ~ifelse(grepl(term, .),1,0))) %>%
group_by(Year) %>%
summarise(has_term = sum(has_term),
total = n())%>%
mutate(prop = has_term/total)%>%
ggplot(aes(x = Year, y = prop))+
geom_line()+
theme_minimal()+
labs(title = paste0("Proportion of articles on a topic that are also about ", term))+
scale_x_continuous(breaks= pretty_breaks())
term <- "battered"
df %>%
mutate(has_term = map_dbl(All_text, ~ifelse(grepl(term, .),1,0))) %>%
group_by(Year) %>%
summarise(has_term = sum(has_term),
total = n())%>%
mutate(prop = has_term/total)%>%
ggplot(aes(x = Year, y = prop))+
geom_line()+
theme_minimal()+
labs(title = paste0("Proportion of articles on a topic that are also about ", term))+
scale_x_continuous(breaks= pretty_breaks())
df %>%
mutate(has_term = map_dbl(All_text, ~ifelse(grepl(term, .),1,0))) %>%
group_by(Year) %>%
summarise(has_term = sum(has_term),
total = n())%>%
mutate(prop = has_term/total)%>%
ggplot(aes(x = Year, y = prop))+
geom_line()+
theme_minimal()+
labs(title = paste0('Proportion of articles on a topic that feature the term "', term, '"'))+
scale_x_continuous(breaks= pretty_breaks())
#term <- "battered"
term <- "maltreatment"
df %>%
mutate(has_term = map_dbl(All_text, ~ifelse(grepl(term, .),1,0))) %>%
group_by(Year) %>%
summarise(has_term = sum(has_term),
total = n())%>%
mutate(prop = has_term/total)%>%
ggplot(aes(x = Year, y = prop))+
geom_line()+
theme_minimal()+
labs(title = paste0('Proportion of articles on a topic that feature the term "', term, '"'))+
scale_x_continuous(breaks= pretty_breaks())
term <- "brain"
df %>%
mutate(has_term = map_dbl(All_text, ~ifelse(grepl(term, .),1,0))) %>%
group_by(Year) %>%
summarise(has_term = sum(has_term),
total = n())%>%
mutate(prop = has_term/total)%>%
ggplot(aes(x = Year, y = prop))+
geom_line()+
theme_minimal()+
labs(title = paste0('Proportion of articles on a topic that feature the term "', term, '"'))+
scale_x_continuous(breaks= pretty_breaks())
